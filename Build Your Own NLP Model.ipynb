{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible = gutenberg.raw('bible-kjv.txt')\n",
    "moby_dick = gutenberg.raw('melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    text = re.sub(r'CHAPTER \\d+', '', text)\n",
    "    text = re.sub(\"\\\\n\\\\n.*?\\\\n\\\\n\", '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "bible = text_cleaner(bible[0:70000])\n",
    "moby_dick = text_cleaner(moby_dick[0:70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "bible_doc = nlp(bible)\n",
    "moby_dick_doc = nlp(moby_dick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(The, First, Book, of, Moses, :)</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Called, Genesis, 1:2)</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(And, the, earth, was, without, form, ,, and, ...</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(And, the, Spirit, of, God, moved, upon, the, ...</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(And, God, saw, the, light, ,, that, it, was, ...</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0      1\n",
       "0                   (The, First, Book, of, Moses, :)  bible\n",
       "1                             (Called, Genesis, 1:2)  bible\n",
       "2  (And, the, earth, was, without, form, ,, and, ...  bible\n",
       "3  (And, the, Spirit, of, God, moved, upon, the, ...  bible\n",
       "4  (And, God, saw, the, light, ,, that, it, was, ...  bible"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_sents = [[sent, 'bible'] for sent in bible_doc.sents]\n",
    "moby_sents = [[sent, 'moby_dick'] for sent in moby_dick_doc.sents]\n",
    "sents = pd.DataFrame(bible_sents + moby_sents)\n",
    "sents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God set them in the firmament of the heaven to give light upon the earth, 1:18 And to rule over the day and over the night, and to divide the light from the darkness: and God saw that it was good.1:20 And God said, Let the waters bring forth abundantly the moving creature that hath life, and fowl that may fly above the earth in the open firmament of heaven. 1:21 And God created great whales, and every living creature that moveth, which the waters brought forth abundantly, after their kind, and every winged fowl after his kind: and God saw that it was good. 1:22 And God blessed them, saying, Be fruitful, and multiply, and fill the waters in the seas, and let fowl multiply in the earth.1:24 And God said, Let the earth bring forth the living creature after his kind, cattle, and creeping thing, and beast of the earth after his kind: and it was so. 1:25 And God made the beast of the earth after his kind, and cattle after their kind, and every thing that creepeth upon the earth after his kind: and God saw that it was good. 1:26 And God said, Let us make man in our image, after our likeness: and let them have dominion over the fish of the sea, and over the fowl of the air, and over the cattle, and over all the earth, and over every creeping thing that creepeth upon the earth. 1:27 So God created man in his own image, in the image of God created he him; male and female created he them. 1:28 And God blessed them, and God said unto them, Be fruitful, and multiply, and replenish the earth, and subdue it: and have dominion over the fish of the sea, and over the fowl of the air, and over every living thing that moveth upon the earth. 1:29 And God said, Behold, I have given you every herb bearing seed, which is upon the face of all the earth, and every tree, in the which is the fruit of a\n",
      "\n",
      " Bible length: 15352\n",
      "\n",
      " what has been promiscuously said, thought, fancied, and sung of Leviathan, by many nations and generations, including our own. So fare thee well, poor devil of a Sub-Sub, whose commentator I am. Thou belongest to that hopeless, sallow tribe which no wine of this world will ever warm; and for whom even Pale Sherry would be too rosy-strong; but with whom one sometimes loves to sit, and feel poor-devilish, too; and grow convivial upon tears; and say to them bluntly, with full eyes and empty glasses, and in not altogether unpleasant sadness Give it up, Sub-Subs! For by how much the more pains ye take to please the world, by so much the more shall ye for ever go thankless! Would that I could clear out Hampton Court and the Tuileries for ye! But gulp down your tears and hie aloft to the royal-mast with your hearts; for your friends who have gone before are clearing out the seven-storied heavens, and making refugees of long-pampered Gabriel, Michael, and Raphael, against your coming. Here ye strike but splintered hearts together there, ye shall strike unsplinterable glasses! EXTRACTS. \"And God created great whales.\" GENESIS. \"Leviathan maketh a path to shine after him; One would think the deep to be hoary.\" JOB. \"Now the Lord had prepared a great fish to swallow up Jonah.\" JONAH. \"There go the ships; there is that Leviathan whom thou hast made to play therein.\" PSALMS. \"In that day, the Lord with his sore, and great, and strong sword, shall punish Leviathan the piercing serpent, even Leviathan that crooked serpent; and he shall slay the dragon that is in the sea.\" ISAIAH \"And what thing soever besides cometh within the chaos of this monster's mouth, be it beast, boat, or stone, down it goes all incontinently that foul great swallow of his, and perisheth in the bottomless gulf of his paunch.\" HOLLAND'S PLUTARCH'S MORALS\n",
      "\n",
      " Moby Dick length: 14710\n"
     ]
    }
   ],
   "source": [
    "print(bible_doc[400:800])\n",
    "print('\\n Bible length:', len(bible_doc))\n",
    "\n",
    "print('\\n', moby_dick_doc[400:800])\n",
    "print('\\n Moby Dick length:', len(moby_dick_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words & Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoW\n",
    "def bag_of_words(text):\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    return [item[0] for item in Counter(allwords).most_common(800)]\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "    return df\n",
    "\n",
    "bible_words = bag_of_words(bible_doc)\n",
    "moby_words = bag_of_words(moby_dick_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2:7</th>\n",
       "      <th>healthy</th>\n",
       "      <th>harris</th>\n",
       "      <th>flesh</th>\n",
       "      <th>supper</th>\n",
       "      <th>see</th>\n",
       "      <th>here</th>\n",
       "      <th>therefore</th>\n",
       "      <th>4:17</th>\n",
       "      <th>4:19</th>\n",
       "      <th>...</th>\n",
       "      <th>hair</th>\n",
       "      <th>shoal</th>\n",
       "      <th>forecastle</th>\n",
       "      <th>dismal</th>\n",
       "      <th>queen</th>\n",
       "      <th>soon</th>\n",
       "      <th>presently</th>\n",
       "      <th>deal</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, First, Book, of, Moses, :)</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Called, Genesis, 1:2)</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(And, the, earth, was, without, form, ,, and, ...</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(And, the, Spirit, of, God, moved, upon, the, ...</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(And, God, saw, the, light, ,, that, it, was, ...</td>\n",
       "      <td>bible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  2:7 healthy harris flesh supper see here therefore 4:17 4:19     ...      \\\n",
       "0   0       0      0     0      0   0    0         0    0    0     ...       \n",
       "1   0       0      0     0      0   0    0         0    0    0     ...       \n",
       "2   0       0      0     0      0   0    0         0    0    0     ...       \n",
       "3   0       0      0     0      0   0    0         0    0    0     ...       \n",
       "4   0       0      0     0      0   1    0         0    0    0     ...       \n",
       "\n",
       "  hair shoal forecastle dismal queen soon presently deal  \\\n",
       "0    0     0          0      0     0    0         0    0   \n",
       "1    0     0          0      0     0    0         0    0   \n",
       "2    0     0          0      0     0    0         0    0   \n",
       "3    0     0          0      0     0    0         0    0   \n",
       "4    0     0          0      0     0    0         0    0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0                   (The, First, Book, of, Moses, :)       bible  \n",
       "1                             (Called, Genesis, 1:2)       bible  \n",
       "2  (And, the, earth, was, without, form, ,, and, ...       bible  \n",
       "3  (And, the, Spirit, of, God, moved, upon, the, ...       bible  \n",
       "4  (And, God, saw, the, light, ,, that, it, was, ...       bible  \n",
       "\n",
       "[5 rows x 1410 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonwords = set(bible_words + moby_words)\n",
    "word_counts = bow_features(sents, commonwords)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "bible = gutenberg.sents('bible-kjv.txt')\n",
    "moby = gutenberg.sents('melville-moby_dick.txt')\n",
    "bible_list = [\" \".join(sent) for sent in bible]\n",
    "moby_list = [\" \".join(sent) for sent in moby]\n",
    "joined = bible_list + moby_list\n",
    "vectorizer = TfidfVectorizer(max_df=0.25, \n",
    "                             min_df=3, \n",
    "                             stop_words='english',   \n",
    "                             use_idf=True,\n",
    "                             norm=u'l2', \n",
    "                             smooth_idf=True \n",
    "                            )\n",
    "tfidf = vectorizer.fit_transform(joined).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = word_counts\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = bow['text_source']\n",
    "X_tfidf = tfidf\n",
    "Y_tfidf = ['bible']*len(bible_list) + ['moby_dick']*len(moby_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Models: LR, RF, GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the performances of BoW and tfidf with three supervised models - logistic regression, random forest, and gradient boosting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW LR Scores:  [0.80838323 0.83233533 0.84084084 0.87387387 0.92168675]\n",
      "Avg LR Score: 0.8554240049153836\n",
      "\n",
      "tfidf LR Scores: [0.96900286 0.97360886 0.95929292 0.97011952 0.93848836]\n",
      "Avg Score: 0.9621025045745585\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "bow_lr = lr.fit(X_bow, Y_bow)\n",
    "print('BoW LR Scores: ', cross_val_score(bow_lr, X_bow, Y_bow, cv=5))\n",
    "print('Avg LR Score:', np.mean(cross_val_score(bow_lr, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "tfidf_lr = lr.fit(X_tfidf, Y_tfidf)\n",
    "print('\\ntfidf LR Scores:', cross_val_score(tfidf_lr, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(tfidf_lr, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow Gradient Boosting Scores: [0.75449102 0.81437126 0.8048048  0.81081081 0.89156627]\n",
      "Avg Score: 0.8176112336273942\n",
      "\n",
      "Tfidf Random Forest Scores: [0.81949458 0.84588572 0.86169551 0.84860558 0.84074212]\n",
      "Avg Score: 0.8434340494364818\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gb = ensemble.GradientBoostingClassifier()\n",
    "bow_gb = gb.fit(X_bow, Y_bow)\n",
    "print('Bow Gradient Boosting Scores:', cross_val_score(bow_gb, X_bow,Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(bow_gb, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "tfidf_gb = gb.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Random Forest Scores:', cross_val_score(tfidf_gb, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(tfidf_gb, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Random Forest Scores:  [0.78742515 0.83832335 0.84384384 0.88888889 0.92168675]\n",
      "Avg Score: 0.8584143879829617\n",
      "\n",
      "Tfidf Random Forest Scores: [0.94149135 0.94671978 0.9455994  0.94459661 0.92641016]\n",
      "Avg Score: 0.9399673273725657\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf_bow = rf.fit(X_bow, Y_bow)\n",
    "print('BoW Random Forest Scores: ', cross_val_score(rf_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(rf_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "tfidf_rf = rf.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Random Forest Scores:', cross_val_score(tfidf_rf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(tfidf_rf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-idf performed at higher scores and show greater consistency than its BoW counterparts, which generated scores that varied greatly. We will take a lot at ways to improve the score for tf-idf - specifically for gradient boosting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf Gradient Boosting: Increase Accuracy by 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8520257532102586\n",
      "\n",
      "Test score: 0.8550917088555067\n"
     ]
    }
   ],
   "source": [
    "X_tfidf_train, X_tfidf_test, Y_tfidf_train, Y_tfidf_test = train_test_split(X_tfidf, \n",
    "                                                    Y_tfidf,\n",
    "                                                    test_size=0.3)\n",
    "\n",
    "train = gb.fit(X_tfidf, Y_tfidf)\n",
    "\n",
    "print('Train score:', gb.score(X_tfidf_train, Y_tfidf_train))\n",
    "print('\\nTest score:', gb.score(X_tfidf_test, Y_tfidf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No glaring overfitting issues here. We will seek to increase this score by 5% (90%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:\n",
      "0.8988368370504749\n"
     ]
    }
   ],
   "source": [
    "gb_parameters = {\n",
    "             'n_estimators':[100,200],\n",
    "              'max_depth':[2,4],\n",
    "             'max_features':['auto']\n",
    "}\n",
    "gb_grid = GridSearchCV(gb, gb_parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "gb_grid.fit(X_tfidf_train, Y_tfidf_train)\n",
    "print('Best Score:')\n",
    "print(gb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was close! The score rose from 0.855 initially to 0.899. This means the model is close to 90% when it comes to making right predictions. This makes for an effective model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
